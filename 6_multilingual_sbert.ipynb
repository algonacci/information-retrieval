{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_name = \"sentence-transformers/paraphrase-distilroberta-base-v2\"\n",
    "student_model_name = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_len(d):\n",
    "    d = d[\"translation\"]\n",
    "    return len(d[\"en\"]) > 30 and len(d[\"en\"]) < 64 and len(d[\"hi\"]) > 20 and len(d[\"hi\"]) < 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration cfilt--iitb-english-hindi-911387c6837f8b91\n",
      "Reusing dataset parquet (/home/utsav/.cache/huggingface/datasets/cfilt___parquet/cfilt--iitb-english-hindi-911387c6837f8b91/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n",
      "Parameter 'function'=<function <lambda> at 0x7f07149691f0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Loading cached processed dataset at /home/utsav/.cache/huggingface/datasets/cfilt___parquet/cfilt--iitb-english-hindi-911387c6837f8b91/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8/cache-08577eb1924770d3.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(133571,\n",
       " {'translation': {'en': 'The default plugin layout for the top panel',\n",
       "   'hi': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"cfilt/iitb-english-hindi\", split=\"train\")\n",
    "\n",
    "dataset = dataset.filter(lambda x: True if is_valid_len(x) and (random.random() > 0.8) else False)\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'The default plugin layout for the top panel',\n",
       "  'hi': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.8 s, sys: 8.4 s, total: 1min 8s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "teacher_tokenized_en = teacher_tokenizer([data[\"translation\"][\"en\"] for data in dataset],\n",
    "                                         max_length=64, padding=\"max_length\",\n",
    "                                         truncation=True, verbose=True)\n",
    "\n",
    "student_tokenized_en = student_tokenizer([data[\"translation\"][\"en\"] for data in dataset],\n",
    "                                         max_length=64, padding=\"max_length\",\n",
    "                                         truncation=True, verbose=True)\n",
    "\n",
    "student_tokenized_hi = student_tokenizer([data[\"translation\"][\"hi\"] for data in dataset],\n",
    "                                         max_length=64, padding=\"max_length\",\n",
    "                                         truncation=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnHiDataset:\n",
    "    def __init__(self, teacher_en_tokens: dict, student_en_tokens: dict, student_hi_tokens: dict):\n",
    "        self.teacher_en_tokens = teacher_en_tokens\n",
    "        self.student_en_tokens = student_en_tokens\n",
    "        self.student_hi_tokens = student_hi_tokens\n",
    "\n",
    "    def __getitem__(self, ix: int) -> dict[str, torch.tensor]:\n",
    "        return {\n",
    "            \"teacher_en_input_ids\": torch.tensor(self.teacher_en_tokens[\"input_ids\"][ix], dtype=torch.long),\n",
    "            \"teacher_en_attention_mask\": torch.tensor(self.teacher_en_tokens[\"attention_mask\"][ix], dtype=torch.long),\n",
    "            \"student_en_input_ids\": torch.tensor(self.student_en_tokens[\"input_ids\"][ix], dtype=torch.long),\n",
    "            \"student_en_attention_mask\": torch.tensor(self.student_en_tokens[\"attention_mask\"][ix], dtype=torch.long),\n",
    "            \"student_hi_input_ids\": torch.tensor(self.student_hi_tokens[\"input_ids\"][ix], dtype=torch.long),\n",
    "            \"student_hi_attention_mask\": torch.tensor(self.student_hi_tokens[\"attention_mask\"][ix], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.teacher_en_tokens[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 7.53 ms, total: 7.53 ms\n",
      "Wall time: 7.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = EnHiDataset(teacher_tokenized_en, student_tokenized_en, student_tokenized_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133571"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * train_ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(token_embeds: torch.tensor, attention_mask: torch.tensor) -> torch.tensor:\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "teacher_model = AutoModel.from_pretrained(teacher_model_name).to(device)\n",
    "student_model = AutoModel.from_pretrained(student_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_out = teacher_model(d[\"teacher_en_input_ids\"].to(device),\n",
    "                                  d[\"teacher_en_attention_mask\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_en_model_out = student_model(d[\"student_en_input_ids\"].to(device),\n",
    "                                     d[\"student_en_attention_mask\"].to(device))\n",
    "\n",
    "student_hi_model_out = student_model(d[\"student_hi_input_ids\"].to(device),\n",
    "                                     d[\"student_hi_attention_mask\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model_out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_en_model_out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_en_pooled = mean_pool(teacher_model_out.last_hidden_state, d[\"teacher_en_attention_mask\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_en_pooled = mean_pool(student_en_model_out.last_hidden_state, d[\"student_en_attention_mask\"].to(device))\n",
    "student_hi_pooled = mean_pool(student_hi_model_out.last_hidden_state, d[\"student_hi_attention_mask\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (teacher_en_pooled - student_en_pooled) ** 2 + (teacher_en_pooled - student_hi_pooled) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7211, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(student_en_pooled, teacher_en_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7246, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(student_hi_pooled, teacher_en_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  optimizer, lr, num_warmup steps have been picked from the paper\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_dataset) // batch_size\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps - warmup_steps)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_step_fn(teacher_model: torch.nn.Module, student_model: torch.nn.Module,\n",
    "                      optimizer: torch.optim.Optimizer,\n",
    "                      scheduler: torch.optim.lr_scheduler.LambdaLR,\n",
    "                      loss_fn: torch.nn.CrossEntropyLoss):\n",
    "\n",
    "    def train_step_fn(d: torch.tensor) -> float:\n",
    "        student_model.train()\n",
    "\n",
    "        teacher_model_out = teacher_model(d[\"teacher_en_input_ids\"].to(device),\n",
    "                                          d[\"teacher_en_attention_mask\"].to(device))\n",
    "        teacher_en_pooled = mean_pool(teacher_model_out.last_hidden_state,\n",
    "                                      d[\"teacher_en_attention_mask\"].to(device))\n",
    "\n",
    "        student_en_model_out = student_model(d[\"student_en_input_ids\"].to(device),\n",
    "                                     d[\"student_en_attention_mask\"].to(device))\n",
    "        student_hi_model_out = student_model(d[\"student_hi_input_ids\"].to(device),\n",
    "                                             d[\"student_hi_attention_mask\"].to(device))\n",
    "        student_en_pooled = mean_pool(student_en_model_out.last_hidden_state,\n",
    "                                      d[\"student_en_attention_mask\"].to(device))\n",
    "        student_hi_pooled = mean_pool(student_hi_model_out.last_hidden_state,\n",
    "                                      d[\"student_hi_attention_mask\"].to(device))\n",
    "        \n",
    "        loss = (loss_fn(student_en_pooled, teacher_en_pooled) +\n",
    "                loss_fn(student_hi_pooled, teacher_en_pooled)) / 2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "\n",
    "    return train_step_fn\n",
    "\n",
    "\n",
    "def get_val_step_fn(teacher_model: torch.nn.Module, student_model: torch.nn.Module,\n",
    "                    loss_fn: torch.nn.CrossEntropyLoss):\n",
    "\n",
    "    def val_step_fn(d: torch.tensor) -> float:\n",
    "        student_model.eval()\n",
    "\n",
    "        teacher_model_out = teacher_model(d[\"teacher_en_input_ids\"].to(device),\n",
    "                                          d[\"teacher_en_attention_mask\"].to(device))\n",
    "        teacher_en_pooled = mean_pool(teacher_model_out.last_hidden_state,\n",
    "                                      d[\"teacher_en_attention_mask\"].to(device))\n",
    "\n",
    "        student_en_model_out = student_model(d[\"student_en_input_ids\"].to(device),\n",
    "                                     d[\"student_en_attention_mask\"].to(device))\n",
    "        student_hi_model_out = student_model(d[\"student_hi_input_ids\"].to(device),\n",
    "                                             d[\"student_hi_attention_mask\"].to(device))\n",
    "        student_en_pooled = mean_pool(student_en_model_out.last_hidden_state,\n",
    "                                      d[\"student_en_attention_mask\"].to(device))\n",
    "        student_hi_pooled = mean_pool(student_hi_model_out.last_hidden_state,\n",
    "                                      d[\"student_hi_attention_mask\"].to(device))\n",
    "        \n",
    "        loss = (loss_fn(student_en_pooled, teacher_en_pooled) +\n",
    "                loss_fn(student_hi_pooled, teacher_en_pooled)) / 2\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    return val_step_fn\n",
    "\n",
    "\n",
    "def mini_batch(\n",
    "    dataloader: DataLoader, step_fn: Callable[torch.tensor, torch.tensor], is_training: bool = True\n",
    ") -> tuple[np.array, list[float]]:\n",
    "\n",
    "    mini_batch_losses = []\n",
    "\n",
    "    if is_training:\n",
    "        print(\"\\nTraining ...\")\n",
    "    else:\n",
    "        print(\"\\nValidating ...\")\n",
    "    n_steps = len(dataloader)\n",
    "    for i, data in enumerate(dataloader):\n",
    "        loss = step_fn(data)\n",
    "        mini_batch_losses.append(loss)\n",
    "        if i % (batch_size * 1000) == 0:\n",
    "            print(f\"step {i:>5}/{n_steps}, loss = {loss: .3f}\")\n",
    "\n",
    "    return np.mean(mini_batch_losses), mini_batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ...\n",
      "step     0/53428, loss =  0.733\n",
      "step  2000/53428, loss =  0.263\n",
      "step  4000/53428, loss =  0.256\n",
      "step  6000/53428, loss =  0.271\n",
      "step  8000/53428, loss =  0.242\n",
      "step 10000/53428, loss =  0.214\n",
      "step 12000/53428, loss =  0.217\n",
      "step 14000/53428, loss =  0.222\n",
      "step 16000/53428, loss =  0.202\n",
      "step 18000/53428, loss =  0.198\n",
      "step 20000/53428, loss =  0.168\n",
      "step 22000/53428, loss =  0.242\n",
      "step 24000/53428, loss =  0.145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mmini_batch\u001b[0;34m(dataloader, step_fn, is_training)\u001b[0m\n\u001b[1;32m     73\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 75\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     mini_batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m (batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mget_train_step_fn.<locals>.train_step_fn\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step_fn\u001b[39m(d: torch\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     teacher_model_out \u001b[38;5;241m=\u001b[39m teacher_model(d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher_en_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     10\u001b[0m                                       d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher_en_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     11\u001b[0m     teacher_en_pooled \u001b[38;5;241m=\u001b[39m mean_pool(teacher_model_out\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[1;32m     12\u001b[0m                                   d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher_en_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1732\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1732\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1732\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1732\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module.train at line 1732 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1732\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1732\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1731\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining mode is expected to be boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m-> 1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   1732\u001b[0m     module\u001b[38;5;241m.\u001b[39mtrain(mode)\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1618\u001b[0m, in \u001b[0;36mModule.children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1613\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterator over immediate children modules.\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m    Yields:\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;124;03m        Module: a child module\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m   1619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m module\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1636\u001b[0m, in \u001b[0;36mModule.named_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterator over immediate children modules, yielding both\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;124;03mthe name of the module as well as the module itself.\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m memo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m module \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m   1638\u001b[0m         memo\u001b[38;5;241m.\u001b[39madd(module)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 1\n",
    "\n",
    "train_step_fn = get_train_step_fn(teacher_model, student_model, optimizer, scheduler, loss_fn)\n",
    "val_step_fn = get_val_step_fn(teacher_model, student_model, loss_fn)\n",
    "\n",
    "train_losses, train_mini_batch_losses = [], []\n",
    "val_losses, val_mini_batch_losses = [], []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss, _train_mini_batch_losses = mini_batch(train_dataloader, train_step_fn)\n",
    "    train_mini_batch_losses += _train_mini_batch_losses\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss, _val_mini_batch_losses = mini_batch(val_dataloader, val_step_fn, is_training=False)\n",
    "        val_mini_batch_losses += _val_mini_batch_losses\n",
    "        val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating ...\n",
      "step     0/13358, loss =  0.224\n",
      "step  2000/13358, loss =  0.211\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     val_loss, _val_mini_batch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_step_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     val_mini_batch_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _val_mini_batch_losses\n\u001b[1;32m      4\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mmini_batch\u001b[0;34m(dataloader, step_fn, is_training)\u001b[0m\n\u001b[1;32m     73\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 75\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     mini_batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m (batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mget_val_step_fn.<locals>.val_step_fn\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     43\u001b[0m teacher_en_pooled \u001b[38;5;241m=\u001b[39m mean_pool(teacher_model_out\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[1;32m     44\u001b[0m                               d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher_en_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     46\u001b[0m student_en_model_out \u001b[38;5;241m=\u001b[39m student_model(d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_en_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     47\u001b[0m                              d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_en_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 48\u001b[0m student_hi_model_out \u001b[38;5;241m=\u001b[39m \u001b[43mstudent_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent_hi_input_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent_hi_attention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m student_en_pooled \u001b[38;5;241m=\u001b[39m mean_pool(student_en_model_out\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[1;32m     51\u001b[0m                               d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_en_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     52\u001b[0m student_hi_pooled \u001b[38;5;241m=\u001b[39m mean_pool(student_hi_model_out\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[1;32m     53\u001b[0m                               d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_hi_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:848\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    841\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    842\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    843\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    846\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    847\u001b[0m )\n\u001b[0;32m--> 848\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    861\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    515\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    516\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    517\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:409\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    399\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:336\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    328\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    335\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 336\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    346\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:278\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n\u001b[1;32m    276\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mview(new_context_layer_shape)\n\u001b[0;32m--> 278\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (context_layer, attention_probs) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (context_layer,)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[1;32m    281\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m (past_key_value,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    val_loss, _val_mini_batch_losses = mini_batch(val_dataloader, val_step_fn, is_training=False)\n",
    "    val_mini_batch_losses += _val_mini_batch_losses\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save_pretrained(\"models/student_mutli_enhi.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running mean of the mini batch losses\n",
    "\n",
    "window_size = 32\n",
    "\n",
    "train_mb_running_loss = []\n",
    "for i in range(len(train_mini_batch_losses)-window_size):\n",
    "    train_mb_running_loss.append(np.mean(train_mini_batch_losses[i:i+window_size]))\n",
    "\n",
    "val_mb_running_loss = []\n",
    "for i in range(len(val_mini_batch_losses)-window_size):\n",
    "    val_mb_running_loss.append(np.mean(val_mini_batch_losses[i:i+window_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAI/CAYAAACxotLcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXrElEQVR4nO3d0avl91nv8c9zJuaIqKQlkzbNTM4Ez1w4iGDYhEBvxDaSiSXpxTmQgDbUA0PAQAWlTs0/UBBUiqEh1EKKhVBQ6SAjMY3eRrJT25QwxgzhaMaMzehFFXIRBh8v9sphZ86a2Tt7rZk9k+f1gmHv3+/3/a31DHzZ5J219prq7gAAAEzx3/Z7AAAAgGtJBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwyk37PcBe3HrrrX3kyJH9HgMAALhOvfzyy//a3QeXXbshI+jIkSPZ3Nzc7zEAAIDrVFX94+WueTscAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhlLRFUVfdX1WtVdbaqTi65XlX1lcX1V6rq7kuuH6iqv6uqv1jHPAAAAJezcgRV1YEkTyY5nuRYkkeq6tgly44nObr4cyLJVy+5/oUkZ1adBQAAYCfreCXoniRnu/uN7n43ybNJHrpkzUNJvtFbXkxyS1XdniRVdSjJryT52hpmAQAAuKJ1RNAdSd7cdnxucW63a/4wyReT/OcaZgEAALiidURQLTnXu1lTVZ9J8nZ3v7zjk1SdqKrNqtq8cOHCXuYEAABYSwSdS3J42/GhJG/tcs0nkzxYVf83W2+j+6Wq+pNlT9LdT3f3RndvHDx4cA1jAwAAE60jgl5KcrSq7qqqm5M8nOTUJWtOJfnc4lPi7k3yo+4+391f6u5D3X1kcd9fd/evrmEmAACApW5a9QG6+2JVPZ7kuSQHkny9u1+tqscW159KcjrJA0nOJnknyedXfV4AAIC9qO5Lf33n+rexsdGbm5v7PQYAAHCdqqqXu3tj2bW1/GOpAAAANwoRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjCKCAACAUUQQAAAwiggCAABGEUEAAMAoIggAABhFBAEAAKOIIAAAYBQRBAAAjLKWCKqq+6vqtao6W1Unl1yvqvrK4vorVXX34vzhqvqbqjpTVa9W1RfWMQ8AAMDlrBxBVXUgyZNJjic5luSRqjp2ybLjSY4u/pxI8tXF+YtJfqu7fzbJvUl+Y8m9AAAAa7OOV4LuSXK2u9/o7neTPJvkoUvWPJTkG73lxSS3VNXt3X2+u7+bJN39H0nOJLljDTMBAAAstY4IuiPJm9uOz+X/D5kd11TVkSS/kORv1zATAADAUuuIoFpyrj/Imqr6ySR/muQ3u/vflz5J1Ymq2qyqzQsXLux5WAAAYLZ1RNC5JIe3HR9K8tZu11TVj2UrgL7Z3X92uSfp7qe7e6O7Nw4ePLiGsQEAgInWEUEvJTlaVXdV1c1JHk5y6pI1p5J8bvEpcfcm+VF3n6+qSvLHSc509++vYRYAAIArumnVB+jui1X1eJLnkhxI8vXufrWqHltcfyrJ6SQPJDmb5J0kn1/c/skkv5bkB1X1vcW53+3u06vOBQAAsEx1X/rrO9e/jY2N3tzc3O8xAACA61RVvdzdG8uureUfSwUAALhRiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGCUtURQVd1fVa9V1dmqOrnkelXVVxbXX6mqu3d7LwAAwDqtHEFVdSDJk0mOJzmW5JGqOnbJsuNJji7+nEjy1Q9wLwAAwNqs45Wge5Kc7e43uvvdJM8meeiSNQ8l+UZveTHJLVV1+y7vBQAAWJt1RNAdSd7cdnxucW43a3ZzLwAAwNqsI4Jqybne5Zrd3Lv1AFUnqmqzqjYvXLjwAUcEAADYso4IOpfk8LbjQ0ne2uWa3dybJOnup7t7o7s3Dh48uPLQAADATOuIoJeSHK2qu6rq5iQPJzl1yZpTST63+JS4e5P8qLvP7/JeAACAtblp1Qfo7otV9XiS55IcSPL17n61qh5bXH8qyekkDyQ5m+SdJJ+/0r2rzgQAAHA51b30V3CuaxsbG725ubnfYwAAANepqnq5uzeWXVvLP5YKAABwoxBBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCtFUFV9tKqer6rXF18/cpl191fVa1V1tqpObjv/e1X191X1SlX9eVXdsso8AAAAO1n1laCTSV7o7qNJXlgcv09VHUjyZJLjSY4leaSqji0uP5/k57r755P8Q5IvrTgPAADAFa0aQQ8leWbx/TNJPrtkzT1Jznb3G939bpJnF/elu/+quy8u1r2Y5NCK8wAAAFzRqhH0se4+nySLr7ctWXNHkje3HZ9bnLvUryf5yxXnAQAAuKKbdlpQVd9J8vEll57Y5XPUknN9yXM8keRikm9eYY4TSU4kyZ133rnLpwYAAHi/HSOouz99uWtV9cOqur27z1fV7UneXrLsXJLD244PJXlr22M8muQzST7V3Z3L6O6nkzydJBsbG5ddBwAAcCWrvh3uVJJHF98/muTbS9a8lORoVd1VVTcneXhxX6rq/iS/k+TB7n5nxVkAAAB2tGoEfTnJfVX1epL7Fsepqk9U1ekkWXzwweNJnktyJsm3uvvVxf1/lOSnkjxfVd+rqqdWnAcAAOCKdnw73JV0978l+dSS828leWDb8ekkp5es+5+rPD8AAMAHteorQQAAADcUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIyyUgRV1Uer6vmqen3x9SOXWXd/Vb1WVWer6uSS679dVV1Vt64yDwAAwE5WfSXoZJIXuvtokhcWx+9TVQeSPJnkeJJjSR6pqmPbrh9Ocl+Sf1pxFgAAgB2tGkEPJXlm8f0zST67ZM09Sc529xvd/W6SZxf3vecPknwxSa84CwAAwI5WjaCPdff5JFl8vW3JmjuSvLnt+NziXKrqwST/3N3fX3EOAACAXblppwVV9Z0kH19y6YldPkctOddV9ROLx/jlXT1I1YkkJ5Lkzjvv3OVTAwAAvN+OEdTdn77ctar6YVXd3t3nq+r2JG8vWXYuyeFtx4eSvJXkZ5LcleT7VfXe+e9W1T3d/S9L5ng6ydNJsrGx4a1zAADAnqz6drhTSR5dfP9okm8vWfNSkqNVdVdV3Zzk4SSnuvsH3X1bdx/p7iPZiqW7lwUQAADAuqwaQV9Ocl9VvZ6tT3j7cpJU1Seq6nSSdPfFJI8neS7JmSTf6u5XV3xeAACAPdnx7XBX0t3/luRTS86/leSBbcenk5ze4bGOrDILAADAbqz6ShAAAMANRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIwiggAAgFGqu/d7hg+sqi4k+cf9noMd3ZrkX/d7CG5I9g57Yd+wF/YNe2Hf3Bj+R3cfXHbhhowgbgxVtdndG/s9Bzcee4e9sG/YC/uGvbBvbnzeDgcAAIwiggAAgFFEEFfT0/s9ADcse4e9sG/YC/uGvbBvbnB+JwgAABjFK0EAAMAoIoiVVNVHq+r5qnp98fUjl1l3f1W9VlVnq+rkkuu/XVVdVbde/anZb6vum6r6var6+6p6par+vKpuuWbDc83t4udHVdVXFtdfqaq7d3svH1573TdVdbiq/qaqzlTVq1X1hWs/PftllZ83i+sHqurvquovrt3U7IUIYlUnk7zQ3UeTvLA4fp+qOpDkySTHkxxL8khVHdt2/XCS+5L80zWZmOvBqvvm+SQ/190/n+QfknzpmkzNNbfTz4+F40mOLv6cSPLVD3AvH0Kr7JskF5P8Vnf/bJJ7k/yGfTPDivvmPV9IcuYqj8oaiCBW9VCSZxbfP5Pks0vW3JPkbHe/0d3vJnl2cd97/iDJF5P4BbU5Vto33f1X3X1xse7FJIeu7rjso51+fmRx/I3e8mKSW6rq9l3ey4fTnvdNd5/v7u8mSXf/R7b+g/aOazk8+2aVnzepqkNJfiXJ167l0OyNCGJVH+vu80my+HrbkjV3JHlz2/G5xblU1YNJ/rm7v3+1B+W6stK+ucSvJ/nLtU/I9WI3++Bya3a7h/jwWWXf/D9VdSTJLyT52/WPyHVo1X3zh9n6n7r/eZXmY41u2u8BuP5V1XeSfHzJpSd2+xBLznVV/cTiMX55r7Nx/bpa++aS53giW29d+eYHm44byI774AprdnMvH06r7Juti1U/meRPk/xmd//7Gmfj+rXnfVNVn0nydne/XFW/uO7BWD8RxI66+9OXu1ZVP3zv7QOLl4PfXrLsXJLD244PJXkryc8kuSvJ96vqvfPfrap7uvtf1vYXYF9cxX3z3mM8muQzST7VPuv/w+yK+2CHNTfv4l4+nFbZN6mqH8tWAH2zu//sKs7J9WWVffO/kjxYVQ8k+fEkP11Vf9Ldv3oV52UF3g7Hqk4leXTx/aNJvr1kzUtJjlbVXVV1c5KHk5zq7h90923dfaS7j2TrB8vdAmiEPe+bZOvTe5L8TpIHu/udazAv++ey+2CbU0k+t/jUpnuT/GjxNsvd3MuH0573TW39X7k/TnKmu3//2o7NPtvzvunuL3X3ocV/zzyc5K8F0PXNK0Gs6stJvlVV/ydbn+72v5Okqj6R5Gvd/UB3X6yqx5M8l+RAkq9396v7NjHXg1X3zR8l+e9Jnl+8ivhidz92rf8SXH2X2wdV9dji+lNJTid5IMnZJO8k+fyV7t2HvwbX2Cr7Jsknk/xakh9U1fcW5363u09fw78C+2DFfcMNpryLBAAAmMTb4QAAgFFEEAAAMIoIAgAARhFBAADAKCIIAAAYRQQBAACjiCAAAGAUEQQAAIzyX1c8ku7Do1tzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fix, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.plot(range(len(train_mb_running_loss)), train_mb_running_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reranking(\n",
    "    tokenizer: AutoTokenizer, model: AutoModel, device: str, query: str, corpus: list[str]\n",
    ") -> None:\n",
    "    \n",
    "    query_embed = \\\n",
    "    mean_pool(model(\n",
    "        **tokenizer(query, return_tensors=\"pt\").to(device)\n",
    "    ).last_hidden_state,\n",
    "              tokenizer(query, return_tensors=\"pt\")[\"attention_mask\"].to(device)\n",
    "             )\n",
    "\n",
    "    corpus_last_hidden_state = model(\n",
    "        **tokenizer(corpus, max_length=64, padding=True,\n",
    "                    truncation=True, return_tensors=\"pt\").to(device)\n",
    "    ).last_hidden_state\n",
    "    corpus_embeds = mean_pool(corpus_last_hidden_state,\n",
    "                              tokenizer(\n",
    "                                  corpus, max_length=64, padding=True,\n",
    "                                  truncation=True, return_tensors=\"pt\"\n",
    "                              )[\"attention_mask\"].to(device)\n",
    "                             )\n",
    "\n",
    "    scores = torch.nn.CosineSimilarity()(query_embed, corpus_embeds)\n",
    "    \n",
    "    print(f\"Query - {query}\\n---\")\n",
    "    scores = scores.cpu().detach().numpy()\n",
    "    scores_ix = np.argsort(scores)[::-1]\n",
    "    for ix in scores_ix:\n",
    "        print(f\"{scores[ix]: >.2f}\\t{corpus[ix]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "original_student_model = AutoModel.from_pretrained(student_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who let the dogs out\"\n",
    "\n",
    "corpus = [\n",
    "    \"A frog jumped in the pond\",\n",
    "    \"My car broke down last night\",\n",
    "    \"किसने कुत्तों को खुला छोड़ा\",\n",
    "    \"Where are my dogs?\",\n",
    "    \"Are the dogs outside?\",\n",
    "    \"मेरी कार टूट गई\",\n",
    "    \"I wonder if they have reached home\",\n",
    "    \"मुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - My car broke down on the highway\n",
      "---\n",
      "0.95\tमेरी कार हाईवे पर खराब हो गई\n",
      "0.94\tMy car broke down last night\n",
      "0.91\tमेरी कार टूट गई\n",
      "0.75\tThe roads on the highway were bad.\n",
      "0.27\tI wonder if they have reached home\n",
      "0.25\tमुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\n",
      "0.22\tकिसने कुत्तों को खुला छोड़ा\n",
      "0.20\tWhere are my dogs?\n",
      "0.11\tAre the dogs outside?\n"
     ]
    }
   ],
   "source": [
    "compare_reranking(student_tokenizer, student_model, \"cuda\", query, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - My car broke down on the highway\n",
      "---\n",
      "1.00\tThe roads on the highway were bad.\n",
      "1.00\tMy car broke down last night\n",
      "1.00\tमेरी कार हाईवे पर खराब हो गई\n",
      "1.00\tमुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\n",
      "1.00\tI wonder if they have reached home\n",
      "1.00\tAre the dogs outside?\n",
      "0.99\tकिसने कुत्तों को खुला छोड़ा\n",
      "0.99\tWhere are my dogs?\n",
      "0.99\tमेरी कार टूट गई\n"
     ]
    }
   ],
   "source": [
    "compare_reranking(student_tokenizer, original_student_model, \"cpu\", query, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"My car broke down on the highway\"\n",
    "\n",
    "corpus = [\n",
    "    \"The roads on the highway were bad.\",\n",
    "    \"My car broke down last night\",\n",
    "    \"किसने कुत्तों को खुला छोड़ा\",\n",
    "    \"Where are my dogs?\",\n",
    "    \"Are the dogs outside?\",\n",
    "    \"मेरी कार टूट गई\",\n",
    "    \"मेरी कार हाईवे पर खराब हो गई\",\n",
    "    \"I wonder if they have reached home\",\n",
    "    \"मुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - My car broke down on the highway\n",
      "---\n",
      "0.95\tमेरी कार हाईवे पर खराब हो गई\n",
      "0.94\tMy car broke down last night\n",
      "0.91\tमेरी कार टूट गई\n",
      "0.75\tThe roads on the highway were bad.\n",
      "0.27\tI wonder if they have reached home\n",
      "0.25\tमुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\n",
      "0.22\tकिसने कुत्तों को खुला छोड़ा\n",
      "0.20\tWhere are my dogs?\n",
      "0.11\tAre the dogs outside?\n"
     ]
    }
   ],
   "source": [
    "compare_reranking(student_tokenizer, student_model, \"cuda\", query, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - My car broke down on the highway\n",
      "---\n",
      "1.00\tThe roads on the highway were bad.\n",
      "1.00\tMy car broke down last night\n",
      "1.00\tमेरी कार हाईवे पर खराब हो गई\n",
      "1.00\tमुझे आश्चर्य है कि क्या वे घर पहुंच गए हैं\n",
      "1.00\tI wonder if they have reached home\n",
      "1.00\tAre the dogs outside?\n",
      "0.99\tकिसने कुत्तों को खुला छोड़ा\n",
      "0.99\tWhere are my dogs?\n",
      "0.99\tमेरी कार टूट गई\n"
     ]
    }
   ],
   "source": [
    "compare_reranking(student_tokenizer, original_student_model, \"cpu\", query, corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
